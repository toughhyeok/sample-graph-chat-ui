{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toughhyeok/sample-graph-chat-ui/blob/main/KeyKGRL_Exercise1_Hands_on_Practice_of_an_Inductive_KGRL_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE_iOBF19iod"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YNynkCh1BV0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faef65bd-1e41-40a9-b243-5a641dd6fc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.4\n",
            "  Downloading numpy-1.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.4 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.4 which is incompatible.\n",
            "bigframes 2.10.0 requires numpy>=1.24.0, but you have numpy 1.23.4 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.23.4 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.4 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\n",
            "mizani 0.13.5 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "opencv-contrib-python 4.11.0.86 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.4 which is incompatible.\n",
            "opencv-python 4.11.0.86 requires numpy>=1.23.5; python_version >= \"3.11\", but you have numpy 1.23.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "plotnine 0.14.6 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.4 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.4 which is incompatible.\n",
            "scipy 1.15.3 requires numpy<2.5,>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.4 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "39485677fa0f4a6e820efb552dcbf3f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-igraph==0.10.2\n",
            "  Downloading python_igraph-0.10.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting igraph==0.10.2 (from python-igraph==0.10.2)\n",
            "  Downloading igraph-0.10.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting texttable>=1.6.2 (from igraph==0.10.2->python-igraph==0.10.2)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading python_igraph-0.10.2-py3-none-any.whl (9.1 kB)\n",
            "Downloading igraph-0.10.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph, python-igraph\n",
            "Successfully installed igraph-0.10.2 python-igraph-0.10.2 texttable-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.0+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.0%2Bcu117-cp311-cp311-linux_x86_64.whl (1807.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0+cu117) (4.14.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 1.8.1 requires torch>=2.0.0, but you have torch 1.13.0+cu117 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 1.13.0+cu117 which is incompatible.\n",
            "torchdata 0.11.0 requires torch>=2, but you have torch 1.13.0+cu117 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 1.13.0+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.0+cu117\n",
            "Collecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.2 requires tqdm>=4.67, but you have tqdm 4.64.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.64.1\n",
            "Collecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.26.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.9.3) (1.23.4)\n",
            "Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.4 which is incompatible.\n",
            "albumentations 2.0.8 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "cvxpy 1.6.6 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "mizani 0.13.5 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "plotnine 0.14.6 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.4 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.4 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.9.3 which is incompatible.\n",
            "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.9.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.9.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.9.3\n",
            "Collecting matplotlib==3.6.2\n",
            "  Downloading matplotlib-3.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (1.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.6.2) (1.17.0)\n",
            "Downloading matplotlib-3.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.10.0 requires matplotlib>=3.7.1, but you have matplotlib 3.6.2 which is incompatible.\n",
            "bigframes 2.10.0 requires numpy>=1.24.0, but you have numpy 1.23.4 which is incompatible.\n",
            "plotnine 0.14.6 requires matplotlib>=3.8.0, but you have matplotlib 3.6.2 which is incompatible.\n",
            "plotnine 0.14.6 requires numpy>=1.23.5, but you have numpy 1.23.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.6.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "7cc3110c961f4bff8ec12f58aeb45b17"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Environment Setup\n",
        "!pip install numpy==1.23.4\n",
        "!pip install python-igraph==0.10.2\n",
        "!pip install torch==1.13.0+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install tqdm==4.64.1\n",
        "!pip install scipy==1.9.3\n",
        "!pip install matplotlib==3.6.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0nPzCP58Oka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcc8212-6d05-406e-90a7-bddd8ea8030d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'InGram'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 156 (delta 51), reused 32 (delta 32), pack-reused 82 (from 1)\u001b[K\n",
            "Receiving objects: 100% (156/156), 15.59 MiB | 5.83 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/InGram\n"
          ]
        }
      ],
      "source": [
        "# Clone Official Repository of InGram\n",
        "!git clone https://github.com/bdi-lab/InGram.git\n",
        "%cd InGram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVOyp2g9pJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4010072c-1234-4574-e72d-b04d9272e57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aZrx2dYNPT7j4TGVBOGqHMdHRwFUBqx5\n",
            "From (redirected): https://drive.google.com/uc?id=1aZrx2dYNPT7j4TGVBOGqHMdHRwFUBqx5&confirm=t&uuid=d25e3b21-3d31-48f2-9ca5-725da487068b\n",
            "To: /content/InGram/ckpt.zip\n",
            "100% 122M/122M [00:02<00:00, 43.0MB/s]\n",
            "Archive:  ckpt.zip\n",
            "   creating: ckpt/best/\n",
            "   creating: ckpt/best/FB-100/\n",
            "  inflating: ckpt/best/FB-100/best.ckpt  \n",
            "  inflating: ckpt/best/FB-100/config.json  \n",
            "   creating: ckpt/best/FB-25/\n",
            "  inflating: ckpt/best/FB-25/best.ckpt  \n",
            "  inflating: ckpt/best/FB-25/config.json  \n",
            "   creating: ckpt/best/FB-50/\n",
            "  inflating: ckpt/best/FB-50/best.ckpt  \n",
            "  inflating: ckpt/best/FB-50/config.json  \n",
            "   creating: ckpt/best/FB-75/\n",
            "  inflating: ckpt/best/FB-75/best.ckpt  \n",
            "  inflating: ckpt/best/FB-75/config.json  \n",
            "   creating: ckpt/best/NELL-995-v1/\n",
            "  inflating: ckpt/best/NELL-995-v1/best.ckpt  \n",
            "  inflating: ckpt/best/NELL-995-v1/config.json  \n",
            "   creating: ckpt/best/NL-0/\n",
            "  inflating: ckpt/best/NL-0/best.ckpt  \n",
            "  inflating: ckpt/best/NL-0/config.json  \n",
            "   creating: ckpt/best/NL-100/\n",
            "  inflating: ckpt/best/NL-100/best.ckpt  \n",
            "  inflating: ckpt/best/NL-100/config.json  \n",
            "   creating: ckpt/best/NL-25/\n",
            "  inflating: ckpt/best/NL-25/best.ckpt  \n",
            "  inflating: ckpt/best/NL-25/config.json  \n",
            "   creating: ckpt/best/NL-50/\n",
            "  inflating: ckpt/best/NL-50/best.ckpt  \n",
            "  inflating: ckpt/best/NL-50/config.json  \n",
            "   creating: ckpt/best/NL-75/\n",
            "  inflating: ckpt/best/NL-75/best.ckpt  \n",
            "  inflating: ckpt/best/NL-75/config.json  \n",
            "   creating: ckpt/best/WK-100/\n",
            "  inflating: ckpt/best/WK-100/best.ckpt  \n",
            "  inflating: ckpt/best/WK-100/config.json  \n",
            "   creating: ckpt/best/WK-25/\n",
            "  inflating: ckpt/best/WK-25/best.ckpt  \n",
            "  inflating: ckpt/best/WK-25/config.json  \n",
            "   creating: ckpt/best/WK-50/\n",
            "  inflating: ckpt/best/WK-50/best.ckpt  \n",
            "  inflating: ckpt/best/WK-50/config.json  \n",
            "   creating: ckpt/best/WK-75/\n",
            "  inflating: ckpt/best/WK-75/best.ckpt  \n",
            "  inflating: ckpt/best/WK-75/config.json  \n"
          ]
        }
      ],
      "source": [
        "# Download InGram's Checkpoints and unzip\n",
        "!gdown https://drive.google.com/uc?id=1aZrx2dYNPT7j4TGVBOGqHMdHRwFUBqx5 -O ckpt.zip\n",
        "!unzip ckpt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyifZJIo9O1T"
      },
      "outputs": [],
      "source": [
        "# Import Modules\n",
        "from relgraph import generate_relation_triplets\n",
        "from dataset import TestNewData\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from model import InGram\n",
        "import torch\n",
        "import numpy as np\n",
        "from utils import get_rank, get_metrics\n",
        "from evaluation import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUFvvj9p72Fh"
      },
      "outputs": [],
      "source": [
        "# Fix Random Seeds\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpE55AZ_bZxx"
      },
      "outputs": [],
      "source": [
        "data_name = \"FB-100\" ## We use FB-100 in this exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCElw3bII3Fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c9d101-dfaf-43e5-c254-4d56fce1fc52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Test Data Statistics-----\n",
            "Message set has 6987 triplets\n",
            "Supervision set has 2329 triplets\n",
            "2624 entities, 77 relations, 11645 triplets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Load Hyperparameters\n",
        "with open(f\"./ckpt/best/{data_name}/config.json\") as f:\n",
        "    configs = json.load(f)\n",
        "\n",
        "# Load Dataset\n",
        "test = TestNewData(f\"./data/{data_name}/\", data_type = \"test\")\n",
        "\n",
        "# Load Model & Checkpoint\n",
        "\n",
        "my_model = InGram(dim_ent = configs['dimension_entity'], hid_dim_ratio_ent = configs['hidden_dimension_ratio_entity'],\n",
        "                  dim_rel = configs['dimension_relation'], hid_dim_ratio_rel = configs['hidden_dimension_ratio_relation'],\n",
        "                  num_bin = configs['num_bin'], num_layer_ent = configs['num_layer_ent'], num_layer_rel = configs['num_layer_rel'],\n",
        "                  num_head = configs['num_head'])\n",
        "my_model = my_model.cuda()\n",
        "\n",
        "my_model.load_state_dict(torch.load(f\"ckpt/best/{data_name}/best.ckpt\")[\"model_state_dict\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtnjJZkiINTD"
      },
      "source": [
        "# Inspecting a Relation Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIvTVXlRIY16"
      },
      "outputs": [],
      "source": [
        "# Create a Relation Graph\n",
        "test_relation_triplets = generate_relation_triplets(test.msg_triplets, test.num_ent, test.num_rel, configs['num_bin'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NHSoJ7jP95F"
      },
      "source": [
        "## Relations that have the highest/lowest affinity scores with relation \"/media_common/netflix_genre/titles\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioq_OPGQQ1T6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13507262-5545-4d99-b83e-63d27b1c5410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========Relations that have the highest affinity scores with \"/media_common/netflix_genre/titles\"===========\n",
            "/media_common/netflix_genre/titles\n",
            "/film/film/release_date_s./film/film_regional_release_date/film_release_distribution_medium_inv\n",
            "/film/film/other_crew./film/film_crew_gig/film_crew_role_inv\n",
            "/film/film/genre_inv\n"
          ]
        }
      ],
      "source": [
        "target_id = test.rel2id['/media_common/netflix_genre/titles']\n",
        "\n",
        "\n",
        "print(\"===========Relations that have the highest affinity scores with \\\"/media_common/netflix_genre/titles\\\"===========\")\n",
        "for r1,r2,s12 in test_relation_triplets:\n",
        "  if r1 == target_id and s12 == 0:\n",
        "    print(test.id2rel[r2%test.num_rel]+ (\"_inv\" if r2>=test.num_rel else \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lF9yGbH8_uO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7110620-03f6-4c3f-ed1e-d395b1440574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========Relations that have the lowest affinity scores with \"/media_common/netflix_genre/titles\"===========\n",
            "/sports/sports_team_location/teams\n",
            "/location/statistical_region/religions./location/religion_percentage/religion\n",
            "/base/aareas/schema/administrative_area/administrative_parent\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants\n",
            "/location/country/capital\n",
            "/olympics/olympic_participating_country/athletes./olympics/olympic_athlete_affiliation/olympics\n",
            "/location/country/form_of_government\n",
            "/base/aareas/schema/administrative_area/administrative_area_type\n",
            "/people/person/places_lived./people/place_lived/location_inv\n",
            "/people/person/spouse_s./people/marriage/location_of_ceremony_inv\n",
            "/base/culturalevent/event/entity_involved_inv\n",
            "/location/statistical_region/religions./location/religion_percentage/religion_inv\n",
            "/base/aareas/schema/administrative_area/administrative_parent_inv\n",
            "/people/ethnicity/geographic_distribution_inv\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to_inv\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants_inv\n",
            "/base/biblioness/bibs_location/country_inv\n"
          ]
        }
      ],
      "source": [
        "print(\"===========Relations that have the lowest affinity scores with \\\"/media_common/netflix_genre/titles\\\"===========\")\n",
        "for r1,r2,s12 in test_relation_triplets:\n",
        "  if r1 == target_id and s12 == configs['num_bin']-1:\n",
        "    print(test.id2rel[r2%test.num_rel]+ (\"_inv\" if r2>=test.num_rel else \"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8QvDJ_q_d9v"
      },
      "source": [
        "## Exercise: choose a relation and find the relations that have the highest/lowest affinity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkfQfPH9D7iZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0670072c-6fc2-4d0c-c5c4-484f080478b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========List of Relations===========\n",
            "/common/topic/webpage./common/webpage/category\n",
            "/common/topic/webpage./common/webpage/category_inv\n",
            "/people/person/religion\n",
            "/people/person/religion_inv\n",
            "/film/film/release_date_s./film/film_regional_release_date/film_release_distribution_medium\n",
            "/film/film/release_date_s./film/film_regional_release_date/film_release_distribution_medium_inv\n",
            "/award/award_winning_work/awards_won./award/award_honor/award_winner\n",
            "/award/award_winning_work/awards_won./award/award_honor/award_winner_inv\n",
            "/film/film/other_crew./film/film_crew_gig/film_crew_role\n",
            "/film/film/other_crew./film/film_crew_gig/film_crew_role_inv\n",
            "/film/film/genre\n",
            "/film/film/genre_inv\n",
            "/music/genre/artists\n",
            "/music/genre/artists_inv\n",
            "/people/cause_of_death/people\n",
            "/people/cause_of_death/people_inv\n",
            "/location/location/contains\n",
            "/location/location/contains_inv\n",
            "/people/person/places_lived./people/place_lived/location\n",
            "/people/person/places_lived./people/place_lived/location_inv\n",
            "/media_common/netflix_genre/titles\n",
            "/media_common/netflix_genre/titles_inv\n",
            "/award/award_nominee/award_nominations./award/award_nomination/award\n",
            "/award/award_nominee/award_nominations./award/award_nomination/award_inv\n",
            "/organization/organization/headquarters./location/mailing_address/state_province_region\n",
            "/organization/organization/headquarters./location/mailing_address/state_province_region_inv\n",
            "/sports/sports_team_location/teams\n",
            "/sports/sports_team_location/teams_inv\n",
            "/people/ethnicity/people\n",
            "/people/ethnicity/people_inv\n",
            "/location/capital_of_administrative_division/capital_of./location/administrative_division_capital_relationship/administrative_division\n",
            "/location/capital_of_administrative_division/capital_of./location/administrative_division_capital_relationship/administrative_division_inv\n",
            "/education/field_of_study/students_majoring./education/education/major_field_of_study\n",
            "/education/field_of_study/students_majoring./education/education/major_field_of_study_inv\n",
            "/soccer/football_team/current_roster./sports/sports_team_roster/position\n",
            "/soccer/football_team/current_roster./sports/sports_team_roster/position_inv\n",
            "/tv/tv_program/genre\n",
            "/tv/tv_program/genre_inv\n",
            "/tv/tv_personality/tv_regular_appearances./tv/tv_regular_personal_appearance/program\n",
            "/tv/tv_personality/tv_regular_appearances./tv/tv_regular_personal_appearance/program_inv\n",
            "/base/popstra/celebrity/dated./base/popstra/dated/participant\n",
            "/base/popstra/celebrity/dated./base/popstra/dated/participant_inv\n",
            "/people/person/spouse_s./people/marriage/location_of_ceremony\n",
            "/people/person/spouse_s./people/marriage/location_of_ceremony_inv\n",
            "/olympics/olympic_games/participating_countries\n",
            "/olympics/olympic_games/participating_countries_inv\n",
            "/film/film/distributors./film/film_film_distributor_relationship/film_distribution_medium\n",
            "/film/film/distributors./film/film_film_distributor_relationship/film_distribution_medium_inv\n",
            "/base/culturalevent/event/entity_involved\n",
            "/base/culturalevent/event/entity_involved_inv\n",
            "/award/award_category/winners./award/award_honor/award_winner\n",
            "/award/award_category/winners./award/award_honor/award_winner_inv\n",
            "/olympics/olympic_sport/athletes./olympics/olympic_athlete_affiliation/country\n",
            "/olympics/olympic_sport/athletes./olympics/olympic_athlete_affiliation/country_inv\n",
            "/sports/sports_team/colors\n",
            "/sports/sports_team/colors_inv\n",
            "/olympics/olympic_participating_country/medals_won./olympics/olympic_medal_honor/olympics\n",
            "/olympics/olympic_participating_country/medals_won./olympics/olympic_medal_honor/olympics_inv\n",
            "/olympics/olympic_sport/athletes./olympics/olympic_athlete_affiliation/olympics\n",
            "/olympics/olympic_sport/athletes./olympics/olympic_athlete_affiliation/olympics_inv\n",
            "/base/x2010fifaworldcupsouthafrica/world_cup_squad/current_world_cup_squad./base/x2010fifaworldcupsouthafrica/current_world_cup_squad/current_club\n",
            "/base/x2010fifaworldcupsouthafrica/world_cup_squad/current_world_cup_squad./base/x2010fifaworldcupsouthafrica/current_world_cup_squad/current_club_inv\n",
            "/organization/endowed_organization/endowment./measurement_unit/dated_money_value/currency\n",
            "/organization/endowed_organization/endowment./measurement_unit/dated_money_value/currency_inv\n",
            "/education/educational_institution/school_type\n",
            "/education/educational_institution/school_type_inv\n",
            "/location/statistical_region/religions./location/religion_percentage/religion\n",
            "/location/statistical_region/religions./location/religion_percentage/religion_inv\n",
            "/language/human_language/countries_spoken_in\n",
            "/language/human_language/countries_spoken_in_inv\n",
            "/film/film/produced_by\n",
            "/film/film/produced_by_inv\n",
            "/base/aareas/schema/administrative_area/administrative_parent\n",
            "/base/aareas/schema/administrative_area/administrative_parent_inv\n",
            "/organization/organization/headquarters./location/mailing_address/country\n",
            "/organization/organization/headquarters./location/mailing_address/country_inv\n",
            "/film/film/prequel\n",
            "/film/film/prequel_inv\n",
            "/film/film/edited_by\n",
            "/film/film/edited_by_inv\n",
            "/government/legislative_session/members./government/government_position_held/district_represented\n",
            "/government/legislative_session/members./government/government_position_held/district_represented_inv\n",
            "/people/deceased_person/place_of_death\n",
            "/people/deceased_person/place_of_death_inv\n",
            "/people/ethnicity/geographic_distribution\n",
            "/people/ethnicity/geographic_distribution_inv\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to_inv\n",
            "/education/educational_degree/people_with_this_degree./education/education/institution\n",
            "/education/educational_degree/people_with_this_degree./education/education/institution_inv\n",
            "/award/award_category/winners./award/award_honor/ceremony\n",
            "/award/award_category/winners./award/award_honor/ceremony_inv\n",
            "/sports/pro_athlete/teams./sports/sports_team_roster/team\n",
            "/sports/pro_athlete/teams./sports/sports_team_roster/team_inv\n",
            "/education/educational_degree/people_with_this_degree./education/education/student\n",
            "/education/educational_degree/people_with_this_degree./education/education/student_inv\n",
            "/travel/travel_destination/climate./travel/travel_destination_monthly_climate/month\n",
            "/travel/travel_destination/climate./travel/travel_destination_monthly_climate/month_inv\n",
            "/base/popstra/location/vacationers./base/popstra/vacation_choice/vacationer\n",
            "/base/popstra/location/vacationers./base/popstra/vacation_choice/vacationer_inv\n",
            "/people/person/employment_history./business/employment_tenure/company\n",
            "/people/person/employment_history./business/employment_tenure/company_inv\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants_inv\n",
            "/film/film/estimated_budget./measurement_unit/dated_money_value/currency\n",
            "/film/film/estimated_budget./measurement_unit/dated_money_value/currency_inv\n",
            "/organization/organization_founder/organizations_founded\n",
            "/organization/organization_founder/organizations_founded_inv\n",
            "/base/schemastaging/person_extra/net_worth./measurement_unit/dated_money_value/currency\n",
            "/base/schemastaging/person_extra/net_worth./measurement_unit/dated_money_value/currency_inv\n",
            "/award/award_nominated_work/award_nominations./award/award_nomination/nominated_for\n",
            "/award/award_nominated_work/award_nominations./award/award_nomination/nominated_for_inv\n",
            "/location/country/capital\n",
            "/location/country/capital_inv\n",
            "/sports/sports_league/teams./sports/sports_league_participation/team\n",
            "/sports/sports_league/teams./sports/sports_league_participation/team_inv\n",
            "/olympics/olympic_participating_country/athletes./olympics/olympic_athlete_affiliation/olympics\n",
            "/olympics/olympic_participating_country/athletes./olympics/olympic_athlete_affiliation/olympics_inv\n",
            "/base/popstra/celebrity/breakup./base/popstra/breakup/participant\n",
            "/base/popstra/celebrity/breakup./base/popstra/breakup/participant_inv\n",
            "/film/film/film_format\n",
            "/film/film/film_format_inv\n",
            "/organization/organization/place_founded\n",
            "/organization/organization/place_founded_inv\n",
            "/user/alexander/philosophy/philosopher/interests\n",
            "/user/alexander/philosophy/philosopher/interests_inv\n",
            "/film/film_set_designer/film_sets_designed\n",
            "/film/film_set_designer/film_sets_designed_inv\n",
            "/music/record_label/artist\n",
            "/music/record_label/artist_inv\n",
            "/film/film/film_festivals\n",
            "/film/film/film_festivals_inv\n",
            "/sports/sports_team/roster./american_football/football_historical_roster_position/position_s\n",
            "/sports/sports_team/roster./american_football/football_historical_roster_position/position_s_inv\n",
            "/location/country/form_of_government\n",
            "/location/country/form_of_government_inv\n",
            "/location/statistical_region/gdp_nominal_per_capita./measurement_unit/dated_money_value/currency\n",
            "/location/statistical_region/gdp_nominal_per_capita./measurement_unit/dated_money_value/currency_inv\n",
            "/base/aareas/schema/administrative_area/administrative_area_type\n",
            "/base/aareas/schema/administrative_area/administrative_area_type_inv\n",
            "/award/award_winning_work/awards_won./award/award_honor/honored_for\n",
            "/award/award_winning_work/awards_won./award/award_honor/honored_for_inv\n",
            "/government/politician/government_positions_held./government/government_position_held/basic_title\n",
            "/government/politician/government_positions_held./government/government_position_held/basic_title_inv\n",
            "/base/biblioness/bibs_location/country\n",
            "/base/biblioness/bibs_location/country_inv\n",
            "/government/politician/government_positions_held./government/government_position_held/jurisdiction_of_office\n",
            "/government/politician/government_positions_held./government/government_position_held/jurisdiction_of_office_inv\n",
            "/sports/sports_position/players./sports/sports_team_roster/position\n",
            "/sports/sports_position/players./sports/sports_team_roster/position_inv\n",
            "/medicine/disease/notable_people_with_this_condition\n",
            "/medicine/disease/notable_people_with_this_condition_inv\n",
            "/olympics/olympic_games/medals_awarded./olympics/olympic_medal_honor/medal\n",
            "/olympics/olympic_games/medals_awarded./olympics/olympic_medal_honor/medal_inv\n"
          ]
        }
      ],
      "source": [
        "## List of relations\n",
        "print(\"===========List of Relations===========\")\n",
        "for rel_name in test.id2rel:\n",
        "  print(rel_name)\n",
        "  print(rel_name+\"_inv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCEM8ELtEQFX"
      },
      "outputs": [],
      "source": [
        "## Choose a relation\n",
        "target_rel = \"\"\n",
        "\n",
        "#target_rel = \"/media_common/netflix_genre/titles_inv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_RLHX0-_hdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa6cc77-87b9-41ca-8255-a5ba384a1185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========Relations that have the highest affinity scores with \"/media_common/netflix_genre/titles\"===========\n",
            "/media_common/netflix_genre/titles\n",
            "/film/film/release_date_s./film/film_regional_release_date/film_release_distribution_medium_inv\n",
            "/film/film/other_crew./film/film_crew_gig/film_crew_role_inv\n",
            "/film/film/genre_inv\n"
          ]
        }
      ],
      "source": [
        "print(f\"===========Relations that have the highest affinity scores with \\\"{target_rel}\\\"===========\")\n",
        "if \"_inv\"!= target_rel[-4:]:\n",
        "  target_id = test.rel2id[target_rel]\n",
        "else:\n",
        "  target_id = test.rel2id[target_rel[:-4]]+test.num_rel\n",
        "for r1,r2,s12 in test_relation_triplets:\n",
        "  if r1 == target_id and s12 == 0:\n",
        "    print(test.id2rel[r2%test.num_rel]+ (\"_inv\" if r2>=test.num_rel else \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsHbQ7iB_h7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ea3275-5cea-450e-9302-9882f691ccc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========Relations that have the lowest affinity scores with \"/media_common/netflix_genre/titles\"===========\n",
            "/sports/sports_team_location/teams\n",
            "/location/statistical_region/religions./location/religion_percentage/religion\n",
            "/base/aareas/schema/administrative_area/administrative_parent\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants\n",
            "/location/country/capital\n",
            "/olympics/olympic_participating_country/athletes./olympics/olympic_athlete_affiliation/olympics\n",
            "/location/country/form_of_government\n",
            "/base/aareas/schema/administrative_area/administrative_area_type\n",
            "/people/person/places_lived./people/place_lived/location_inv\n",
            "/people/person/spouse_s./people/marriage/location_of_ceremony_inv\n",
            "/base/culturalevent/event/entity_involved_inv\n",
            "/location/statistical_region/religions./location/religion_percentage/religion_inv\n",
            "/base/aareas/schema/administrative_area/administrative_parent_inv\n",
            "/people/ethnicity/geographic_distribution_inv\n",
            "/location/statistical_region/places_exported_to./location/imports_and_exports/exported_to_inv\n",
            "/military/military_combatant/military_conflicts./military/military_combatant_group/combatants_inv\n",
            "/base/biblioness/bibs_location/country_inv\n"
          ]
        }
      ],
      "source": [
        "print(f\"===========Relations that have the lowest affinity scores with \\\"{target_rel}\\\"===========\")\n",
        "for r1,r2,s12 in test_relation_triplets:\n",
        "  if r1 == target_id and s12 == configs['num_bin']-1:\n",
        "    print(test.id2rel[r2%test.num_rel]+ (\"_inv\" if r2>=test.num_rel else \"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtE7HQgIGceV"
      },
      "source": [
        "# Reproducing the Results of InGram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXmTsaeKG2ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b302d0f-0417-44fd-c83b-5768d5a2fabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/InGram/model.py:117: UserWarning: scatter_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1615.)\n",
            "  attn_val_max = torch.zeros((num_rel, self.num_head, 1)).cuda().scatter_reduce(dim = 0, \\\n",
            "100%|██████████| 2329/2329 [00:03<00:00, 653.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========LP========\n",
            "MR: 171.5\n",
            "MRR: 0.223\n",
            "Hits@10: 0.371\n",
            "Hits@1: 0.146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    my_model.eval()\n",
        "    msg = torch.tensor(test.msg_triplets).cuda()\n",
        "    sup = torch.tensor(test.sup_triplets).cuda()\n",
        "    relation_triplets = torch.tensor(test_relation_triplets).cuda()\n",
        "    test_init_emb_ent = torch.load(f\"ckpt/best/{data_name}/best.ckpt\")[\"inf_emb_ent\"]\n",
        "    test_init_emb_rel = torch.load(f\"ckpt/best/{data_name}/best.ckpt\")[\"inf_emb_rel\"]\n",
        "    emb_ent, emb_rel = my_model(test_init_emb_ent, test_init_emb_rel, msg, relation_triplets)\n",
        "\n",
        "    head_ranks = []\n",
        "    tail_ranks = []\n",
        "    ranks = []\n",
        "    for triplet in tqdm(sup):\n",
        "        triplet = triplet.unsqueeze(dim = 0)\n",
        "\n",
        "        head_corrupt = triplet.repeat(test.num_ent, 1)\n",
        "        head_corrupt[:,0] = torch.arange(end = test.num_ent)\n",
        "\n",
        "        head_scores = my_model.score(emb_ent, emb_rel, head_corrupt)\n",
        "        head_filters = test.filter_dict[('_', int(triplet[0,1].item()), int(triplet[0,2].item()))]\n",
        "        head_rank = get_rank(triplet, head_scores, head_filters, target = 0)\n",
        "\n",
        "        tail_corrupt = triplet.repeat(test.num_ent, 1)\n",
        "        tail_corrupt[:,2] = torch.arange(end = test.num_ent)\n",
        "\n",
        "        tail_scores = my_model.score(emb_ent, emb_rel, tail_corrupt)\n",
        "        tail_filters = test.filter_dict[(int(triplet[0,0].item()), int(triplet[0,1].item()), '_')]\n",
        "        tail_rank = get_rank(triplet, tail_scores, tail_filters, target = 2)\n",
        "\n",
        "        ranks.append(head_rank)\n",
        "        head_ranks.append(head_rank)\n",
        "        ranks.append(tail_rank)\n",
        "        tail_ranks.append(tail_rank)\n",
        "\n",
        "\n",
        "    print(\"\\n========LP========\")\n",
        "    mr, mrr, hit10, hit3, hit1 = get_metrics(ranks)\n",
        "    print(f\"MR: {mr:.1f}\")\n",
        "    print(f\"MRR: {mrr:.3f}\")\n",
        "    print(f\"Hits@10: {hit10:.3f}\")\n",
        "    print(f\"Hits@1: {hit1:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}