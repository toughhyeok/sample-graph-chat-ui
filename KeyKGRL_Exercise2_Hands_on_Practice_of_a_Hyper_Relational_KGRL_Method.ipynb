{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toughhyeok/sample-graph-chat-ui/blob/main/KeyKGRL_Exercise2_Hands_on_Practice_of_a_Hyper_Relational_KGRL_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "CE_iOBF19iod"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YNynkCh1BV0",
        "outputId": "d9b81589-210a-42fc-ab32-fc760a14785f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.11/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.11/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch==2.0.1+cu117 in /usr/local/lib/python3.11/dist-packages (2.0.1+cu117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu117) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu117) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu117) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu117) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu117) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "!pip install numpy==1.25.2\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install torch==2.0.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Official Repository of MAYPL\n",
        "!git clone https://github.com/bdi-lab/MAYPL.git\n",
        "%cd MAYPL/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0nPzCP58Oka",
        "outputId": "c03bbfe2-3f83-481c-a986-a041ff2ca227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MAYPL'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Counting objects: 100% (259/259), done.\u001b[K\n",
            "remote: Compressing objects: 100% (255/255), done.\u001b[K\n",
            "remote: Total 259 (delta 126), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (259/259), 14.96 MiB | 4.60 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n",
            "/content/MAYPL/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MAYPL's Checkpoints and unzip\n",
        "!mkdir ./ckpt\n",
        "!gdown https://drive.google.com/uc?id=1USr78S0jiw-uBo_SxknOx2axpoJ0oYeV -O ./ckpt/ckpt.zip\n",
        "%cd ckpt\n",
        "!unzip ckpt.zip\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZVOyp2g9pJb",
        "outputId": "2ae1ed7a-89be-4cae-ffbf-1ec91cdb0212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1USr78S0jiw-uBo_SxknOx2axpoJ0oYeV\n",
            "From (redirected): https://drive.google.com/uc?id=1USr78S0jiw-uBo_SxknOx2axpoJ0oYeV&confirm=t&uuid=4401437f-777a-4933-aeaf-a25d7e40cac9\n",
            "To: /content/MAYPL/code/ckpt/ckpt.zip\n",
            "100% 810M/810M [00:11<00:00, 67.6MB/s]\n",
            "/content/MAYPL/code/ckpt\n",
            "Archive:  ckpt.zip\n",
            "   creating: ICML2025/\n",
            "   creating: ICML2025/FB-100/\n",
            "  inflating: ICML2025/FB-100/FB-100_310.ckpt  \n",
            "   creating: ICML2025/FB-25/\n",
            "  inflating: ICML2025/FB-25/FB-25_390.ckpt  \n",
            "   creating: ICML2025/FB-50/\n",
            "  inflating: ICML2025/FB-50/FB-50_320.ckpt  \n",
            "   creating: ICML2025/FB-75/\n",
            "  inflating: ICML2025/FB-75/FB-75_140.ckpt  \n",
            "   creating: ICML2025/MFB-IND/\n",
            "  inflating: ICML2025/MFB-IND/MFB-IND_1550.ckpt  \n",
            "   creating: ICML2025/NL-100/\n",
            "  inflating: ICML2025/NL-100/NL-100_160.ckpt  \n",
            "   creating: ICML2025/NL-25/\n",
            "  inflating: ICML2025/NL-25/NL-25_260.ckpt  \n",
            "   creating: ICML2025/NL-50/\n",
            "  inflating: ICML2025/NL-50/NL-50_390.ckpt  \n",
            "   creating: ICML2025/NL-75/\n",
            "  inflating: ICML2025/NL-75/NL-75_660.ckpt  \n",
            "   creating: ICML2025/WD20K100v1/\n",
            "  inflating: ICML2025/WD20K100v1/WDv1_930.ckpt  \n",
            "   creating: ICML2025/WD20K100v2/\n",
            "  inflating: ICML2025/WD20K100v2/WDv2_490.ckpt  \n",
            "   creating: ICML2025/wd50k-eval/\n",
            "  inflating: ICML2025/wd50k-eval/wd-eval_3000.ckpt  \n",
            "   creating: ICML2025/WikiPeople--eval/\n",
            "  inflating: ICML2025/WikiPeople--eval/WP--eval_2900.ckpt  \n",
            "   creating: ICML2025/WikiPeople/\n",
            "  inflating: ICML2025/WikiPeople/WP_2400.ckpt  \n",
            "   creating: ICML2025/WK-100/\n",
            "  inflating: ICML2025/WK-100/WK-100_410.ckpt  \n",
            "   creating: ICML2025/WK-25/\n",
            "  inflating: ICML2025/WK-25/WK-25_300.ckpt  \n",
            "   creating: ICML2025/WK-50/\n",
            "  inflating: ICML2025/WK-50/WK-50_230.ckpt  \n",
            "   creating: ICML2025/WK-75/\n",
            "  inflating: ICML2025/WK-75/WK-75_250.ckpt  \n",
            "   creating: ICML2025/WP-IND/\n",
            "  inflating: ICML2025/WP-IND/WP-IND_1800.ckpt  \n",
            "/content/MAYPL/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Modules\n",
        "from dataloader import HKG\n",
        "import importlib\n",
        "from tqdm import tqdm\n",
        "from utils import calculate_rank, metrics\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from model import MAYPL\n",
        "import logging\n",
        "import copy"
      ],
      "metadata": {
        "id": "YyifZJIo9O1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a Default Logger\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# Load Dataset\n",
        "WPm = HKG(\"../data/\", \"WikiPeople--eval\", logger, setting = \"Transductive\")\n",
        "\n",
        "# Load Entity Names\n",
        "ent2name = {}\n",
        "name2entid = {}\n",
        "\n",
        "with open(\"../data/WikiPeople--eval/ent2name.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        ent, name = line.strip().split(\"\\t\")\n",
        "        ent2name[ent] = name\n",
        "        name2entid[name] = WPm.ent2id_train[ent]\n",
        "\n",
        "for ent in WPm.ent2id_train:\n",
        "    if ent not in ent2name:\n",
        "        ent2name[ent] = ent\n",
        "\n",
        "# Load Relation Names\n",
        "rel2name = {}\n",
        "name2relid = {}\n",
        "\n",
        "with open(\"../data/WikiPeople--eval/rel2name.txt\", \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "        rel, name = line.strip().split(\"\\t\")\n",
        "        rel2name[rel] = name\n",
        "        name2relid[name] = WPm.rel2id_train[rel]\n",
        "\n",
        "for rel in WPm.rel2id_train:\n",
        "    if rel not in rel2name:\n",
        "        rel2name[rel] = rel\n",
        "\n",
        "# Load Model & Checkpoint\n",
        "\n",
        "my_model_WPm = MAYPL(\n",
        "    dim = 256,\n",
        "    num_head = 32,\n",
        "    num_init_layer = 3,\n",
        "    num_layer = 4,\n",
        "    logger = logger\n",
        ").cuda()\n",
        "my_model_WPm = my_model_WPm.cuda()\n",
        "\n",
        "my_model_WPm.load_state_dict(torch.load(\"ckpt/ICML2025/WikiPeople--eval/WP--eval_2900.ckpt\")[\"model_state_dict\"])\n",
        "\n",
        "my_model_WPm.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCElw3bII3Fc",
        "outputId": "4a2b31d3-c7ef-429c-b5b7-dd7f27b06554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MAYPL(\n",
              "  (init_layers): ModuleList(\n",
              "    (0-2): 3 x Init_Layer(\n",
              "      (drop): Dropout(p=0.2, inplace=False)\n",
              "      (proj_he2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_te2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qe2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_he2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_te2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qe2qr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2he): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2te): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qr2qe): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2r): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qr2r): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2he): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2te): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2qe): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fr2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fr2qr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (emb_ent_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (emb_rel_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0-3): 4 x ANMP_Layer(\n",
              "      (drop): Dropout(p=0.2, inplace=False)\n",
              "      (init_emb_fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (proj_head_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_hpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_head_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_tail_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_pri_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_qual_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_qual_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (ent_attn): Attn(\n",
              "        (drop): Dropout(p=0.2, inplace=False)\n",
              "        (P): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (V): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (K): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (act): PReLU(num_parameters=1)\n",
              "        (emb_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (rel_attn): Attn(\n",
              "        (drop): Dropout(p=0.2, inplace=False)\n",
              "        (P): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (V): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (K): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (act): PReLU(num_parameters=1)\n",
              "        (emb_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (to_fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (to_ent_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (to_rel_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study: Top 3 similar entities/relations to a target in WikiPeople-"
      ],
      "metadata": {
        "id": "EYStV_AXczvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Computes the intial and final representations of the entities and relations\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb_ent, emb_rel, _, _ = my_model_WPm(WPm.pri_inf.clone().detach(), WPm.qual_inf.clone().detach(), WPm.qual2fact_inf, \\\n",
        "                                          WPm.num_ent_inf, WPm.num_rel_inf, \\\n",
        "                                          WPm.hpair_inf.clone().detach(), WPm.hpair_freq_inf, WPm.fact2hpair_inf, \\\n",
        "                                          WPm.tpair_inf.clone().detach(), WPm.tpair_freq_inf, WPm.fact2tpair_inf, \\\n",
        "                                          WPm.qpair_inf.clone().detach(), WPm.qpair_freq_inf, WPm.qual2qpair_inf)\n",
        "\n",
        "    init_ent = emb_ent[0]\n",
        "    init_rel = emb_rel[0]\n",
        "    final_ent = emb_ent[-1]\n",
        "    final_rel = emb_rel[-1]"
      ],
      "metadata": {
        "id": "sBX0EbP1d__e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743766cf-df28-4d68-9196-49d7ee91ed81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/MAYPL/code/model.py:273: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1047.)\n",
            "  r2e = zero4ent.index_reduce(dim = 0, index = idx4e, source = src4r2e, reduce = 'mean', include_self = False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 3 similar entities to the entity \"Vancouver\" based on the initial representations returned by the structure-driven intializer and the final representations of MAYPL"
      ],
      "metadata": {
        "id": "JFjWsF-4geI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = name2entid['Vancouver']\n",
        "\n",
        "### Compute similarity between \"Vancouver\" and the other entities based on the initial representations\n",
        "init_scores = (init_ent[target] * init_ent).sum(dim = 1)\n",
        "\n",
        "sorted_init = torch.argsort(init_scores, descending = True)\n",
        "init_top3 = sorted_init[sorted_init!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 ENTITIES BASED ON INITIAL REPRESENTATIONS========\")\n",
        "for ent in init_top3:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oxtGCmgtZS",
        "outputId": "4218836c-af1c-4425-abef-f37ffbc46342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 ENTITIES BASED ON INITIAL REPRESENTATIONS========\n",
            "Venice\n",
            "Budapest\n",
            "Gothenburg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Compute similarity between \"Vancouver\" and the other entities based on the final representations\n",
        "final_scores = (final_ent[target] * final_ent).sum(dim = 1)\n",
        "\n",
        "sorted_final = torch.argsort(final_scores, descending = True)\n",
        "final_scores_top3 = sorted_final[sorted_final!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 ENTITIES BASED ON FINAL REPRESENTATIONS========\")\n",
        "for ent in final_scores_top3:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "id": "IP6xinUohUyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f165968-ed3d-4f93-c092-d17072c4bb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 ENTITIES BASED ON FINAL REPRESENTATIONS========\n",
            "Toronto\n",
            "Victoria\n",
            "Ottawa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 3 similar entities to the entity \"computer scientist\" based on the initial representations returned by the structure-driven intializer and the final representations of MAYPL"
      ],
      "metadata": {
        "id": "obo5VkYNRHZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = name2entid['computer scientist']\n",
        "\n",
        "### Compute similarity between \"computer scientist\" and the other entities based on the initial representations\n",
        "init_scores = (init_ent[target] * init_ent).sum(dim = 1)\n",
        "\n",
        "sorted_init = torch.argsort(init_scores, descending = True)\n",
        "init_top3 = sorted_init[sorted_init!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 ENTITIES BASED ON INITIAL REPRESENTATIONS========\")\n",
        "for ent in init_top3:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bz4ASB_QBSF",
        "outputId": "0fdcc301-aab9-400c-fa79-bae90c7dab5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 ENTITIES BASED ON INITIAL REPRESENTATIONS========\n",
            "psychologist\n",
            "professeur des universités\n",
            "inventor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Compute similarity between \"computer scientist\" and the other entities based on the final representations\n",
        "final_scores = (final_ent[target] * final_ent).sum(dim = 1)\n",
        "\n",
        "sorted_final = torch.argsort(final_scores, descending = True)\n",
        "final_scores_top3 = sorted_final[sorted_final!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 ENTITIES BASED ON FINAL REPRESENTATIONS========\")\n",
        "for ent in final_scores_top3:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbuT_2s_QBXO",
        "outputId": "601f7bc5-0c15-4588-9c0e-086aacb0ca1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 ENTITIES BASED ON FINAL REPRESENTATIONS========\n",
            "mathematician\n",
            "programmer\n",
            "artificial intelligence researcher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 3 similar relations to the relation \"family\" based on the initial representations returned by the structure-driven intializer and the final representations of MAYPL"
      ],
      "metadata": {
        "id": "mIZgVuksRJAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = name2relid['family']\n",
        "\n",
        "### Compute similarity between relation \"family\" and the other relations based on the initial representations\n",
        "init_scores = (init_rel[target] * init_rel).sum(dim = 1)\n",
        "\n",
        "sorted_init = torch.argsort(init_scores, descending = True)\n",
        "init_top3 = sorted_init[sorted_init!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 RELATIONS BASED ON INITIAL REPRESENTATIONS========\")\n",
        "for rel in init_top3:\n",
        "    print(rel2name[WPm.id2rel_train[rel]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP0VgvZMRTsp",
        "outputId": "38013c89-36b0-4311-e2ea-846f58932c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 RELATIONS BASED ON INITIAL REPRESENTATIONS========\n",
            "manner of death\n",
            "country of citizenship\n",
            "ethnic group\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Compute similarity between relation \"family\" and the other relations based on the final representations\n",
        "final_scores = (final_rel[target] * final_rel).sum(dim = 1)\n",
        "\n",
        "sorted_final = torch.argsort(final_scores, descending = True)\n",
        "final_scores_top3 = sorted_final[sorted_final!=target][:3]\n",
        "\n",
        "print(\"========TOP 3 RELATIONS BASED ON FINAL REPRESENTATIONS========\")\n",
        "for rel in final_scores_top3:\n",
        "    print(rel2name[WPm.id2rel_train[rel]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAZqFQSyRjNA",
        "outputId": "22c107f7-a396-44b5-e7d6-abfacfe2cf7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========TOP 3 RELATIONS BASED ON FINAL REPRESENTATIONS========\n",
            "sibling\n",
            "family name\n",
            "father\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study: MAYPL's top 3 prediction on problems in WikiPeople-"
      ],
      "metadata": {
        "id": "84IOAMugXJEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Representations of Entities and Relations in WikiPeople-\n",
        "with torch.no_grad():\n",
        "    lp_pri_list_rank = []\n",
        "    lp_all_list_rank = []\n",
        "\n",
        "    emb_ent, emb_rel, init_embs_ent, init_embs_rel = my_model_WPm(WPm.pri_inf.clone().detach(), WPm.qual_inf.clone().detach(), WPm.qual2fact_inf, \\\n",
        "                                                              WPm.num_ent_inf, WPm.num_rel_inf, \\\n",
        "                                                              WPm.hpair_inf.clone().detach(), WPm.hpair_freq_inf, WPm.fact2hpair_inf, \\\n",
        "                                                              WPm.tpair_inf.clone().detach(), WPm.tpair_freq_inf, WPm.fact2tpair_inf, \\\n",
        "                                                              WPm.qpair_inf.clone().detach(), WPm.qpair_freq_inf, WPm.qual2qpair_inf)"
      ],
      "metadata": {
        "id": "VDYhmfLw30P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAYPL's predictions for the problem ((Marilyn Monroe, born in, Los Angeles), {(country, USA), (is located in, ?)})"
      ],
      "metadata": {
        "id": "49KeCsjGXeZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem = [[name2entid['Marilyn Monroe'], name2relid['place of birth'], name2entid['Los Angeles']], \\\n",
        "           [[name2relid['country'], name2entid['United States of America']], [name2relid['located in the administrative territorial entity'], WPm.num_ent_train]]]\n",
        "query_pri = torch.tensor([problem[0]]).cuda()\n",
        "query_qual = torch.tensor(problem[1]).cuda()\n",
        "query_qual2fact = torch.tensor([0 for _ in range(len(problem[1]))]).cuda()\n",
        "query_hpair = torch.tensor([problem[0][:2]]).cuda()\n",
        "query_hpair_freq = torch.tensor([1]).cuda()\n",
        "query_fact2hpair = torch.tensor([0]).cuda()\n",
        "query_tpair = torch.tensor([problem[0][2:0:-1]]).cuda()\n",
        "query_tpair_freq = torch.tensor([1]).cuda()\n",
        "query_fact2tpair = torch.tensor([0]).cuda()\n",
        "query_qpair = torch.tensor(problem[1]).cuda()\n",
        "query_qpair_freq = torch.tensor([1 for _ in range(len(problem[1]))]).cuda()\n",
        "query_qual2qpair = torch.arange(len(problem[1])).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred = my_model_WPm.pred(query_pri, query_qual, query_qual2fact, \\\n",
        "                       query_hpair, query_hpair_freq, query_fact2hpair, \\\n",
        "                       query_tpair, query_tpair_freq, query_fact2tpair, \\\n",
        "                       query_qpair, query_qpair_freq, query_qual2qpair, \\\n",
        "                       emb_ent, emb_rel, init_embs_ent, init_embs_rel)\n",
        "  pred_top3 = torch.argsort(pred[0], descending = True)[:3]\n",
        "\n",
        "print(\"=====TOP 3 Predictions=====\")\n",
        "\n",
        "for ent in pred_top3:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brplx9j9YanG",
        "outputId": "74a6105b-a0f7-49ea-b5c9-3bc3898fd023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====TOP 3 Predictions=====\n",
            "California\n",
            "New York\n",
            "New York City\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing predictions for the problems with an identical primary triplet (?, awarded, Oscar for Best Director) but with different qualifiers {(subject of, 60th Oscars), (for work, The Last Emperor)} vs. {(for work, A Beautiful Mind)}"
      ],
      "metadata": {
        "id": "M44iOv_3o7AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem1 = [[WPm.num_ent_train, name2relid['award received'], name2entid['Academy Award for Best Director']], \\\n",
        "            [[name2relid['statement is subject of'], name2entid['60th Academy Awards']], [name2relid['for work'], name2entid['The Last Emperor']]]]\n",
        "problem2 = [[WPm.num_ent_train+1, name2relid['award received'], name2entid['Academy Award for Best Director']], \\\n",
        "            [[name2relid['for work'], name2entid['A Beautiful Mind']]]]\n",
        "query_pri = torch.tensor([problem1[0], problem2[0]]).cuda()\n",
        "query_qual = torch.tensor(problem1[1]+problem2[1]).cuda()\n",
        "query_qual2fact = torch.tensor([0 for _ in range(len(problem1[1]))]+[1 for _ in range(len(problem2[1]))]).cuda()\n",
        "query_hpair = torch.tensor([problem1[0][:2], problem2[0][:2]]).cuda()\n",
        "query_hpair_freq = torch.tensor([1,1]).cuda()\n",
        "query_fact2hpair = torch.tensor([0,1]).cuda()\n",
        "query_tpair = torch.tensor([problem1[0][2:0:-1], problem2[0][2:0:-1]]).cuda()\n",
        "query_tpair_freq = torch.tensor([1,1]).cuda()\n",
        "query_fact2tpair = torch.tensor([0,1]).cuda()\n",
        "query_qpair = torch.tensor(problem1[1]+problem2[1]).cuda()\n",
        "query_qpair_freq = torch.tensor([1 for _ in range(len(problem1[1])+len(problem2[1]))]).cuda()\n",
        "query_qual2qpair = torch.arange(len(problem1[1])+len(problem2[1])).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  preds = my_model_WPm.pred(query_pri, query_qual, query_qual2fact, \\\n",
        "                        query_hpair, query_hpair_freq, query_fact2hpair, \\\n",
        "                        query_tpair, query_tpair_freq, query_fact2tpair, \\\n",
        "                        query_qpair, query_qpair_freq, query_qual2qpair, \\\n",
        "                        emb_ent, emb_rel, init_embs_ent, init_embs_rel)\n",
        "\n",
        "print(\"=====TOP 3 Predictions for ((?, awarded, Oscar for Best Director), {(subject of, 60th Oscars), (for work, The Last Emperor)}) =====\")\n",
        "for ent in torch.argsort(preds[0], descending = True)[:3]:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])\n",
        "\n",
        "print(\"=====TOP 3 Predictions for ((?, awarded, Oscar for Best Director), (for work, A Beautiful Mind)}) =====\")\n",
        "for ent in torch.argsort(preds[1], descending = True)[:3]:\n",
        "    print(ent2name[WPm.id2ent_train[ent]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cWB6k4zpRix",
        "outputId": "083eeb78-09ad-4562-a914-fff514aeb25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====TOP 3 Predictions for ((?, awarded, Oscar for Best Director), {(subject of, 60th Oscars), (for work, The Last Emperor)}) =====\n",
            "Bernardo Bertolucci\n",
            "Miloš Forman\n",
            "David Byrne\n",
            "=====TOP 3 Predictions for ((?, awarded, Oscar for Best Director), (for work, A Beautiful Mind)}) =====\n",
            "Ron Howard\n",
            "James Cameron\n",
            "Steven Spielberg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducing the results of MAYPL on WD20K(100)v2"
      ],
      "metadata": {
        "id": "d4zqg-BlVUHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "default_answer = []\n",
        "wdv2 = HKG(\"../data/\", \"WD20K100v2\", logger, setting = \"Inductive\", msg_add_tr = True)\n",
        "for ent in wdv2.ent2id_train:\n",
        "    default_answer.append(wdv2.ent2id_inf[ent])\n",
        "\n",
        "# Load Model & Checkpoint for WD20K(100)v2\n",
        "\n",
        "my_model_wdv2 = MAYPL(\n",
        "    dim = 256,\n",
        "    num_head = 8,\n",
        "    num_init_layer = 3,\n",
        "    num_layer = 5,\n",
        "    logger = logger\n",
        ").cuda()\n",
        "my_model_wdv2 = my_model_wdv2.cuda()\n",
        "\n",
        "my_model_wdv2.load_state_dict(torch.load(\"ckpt/ICML2025/WD20K100v2/WDv2_490.ckpt\")[\"model_state_dict\"])\n",
        "\n",
        "my_model_wdv2.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGB7NJne2q8p",
        "outputId": "a7f10d0b-df4c-4af1-efb0-124eba1f8d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MAYPL(\n",
              "  (init_layers): ModuleList(\n",
              "    (0-2): 3 x Init_Layer(\n",
              "      (drop): Dropout(p=0.2, inplace=False)\n",
              "      (proj_he2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_te2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qe2e): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_he2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_te2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qe2qr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2he): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2te): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qr2qe): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_pr2r): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qr2r): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2he): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2te): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fe2qe): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fr2pr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fr2qr): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (emb_ent_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (emb_rel_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0-4): 5 x ANMP_Layer(\n",
              "      (drop): Dropout(p=0.2, inplace=False)\n",
              "      (init_emb_fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (proj_head_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_hpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qpair_to_fact): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_rel2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_head_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_tail_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_qual_ent2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_head_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_tail_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_pri_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_qual_ent): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_fact_to_qual_rel): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (ent_attn): Attn(\n",
              "        (drop): Dropout(p=0.2, inplace=False)\n",
              "        (P): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (V): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (K): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (act): PReLU(num_parameters=1)\n",
              "        (emb_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (rel_attn): Attn(\n",
              "        (drop): Dropout(p=0.2, inplace=False)\n",
              "        (P): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (V): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (K): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (act): PReLU(num_parameters=1)\n",
              "        (emb_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (to_fact_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (to_ent_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (to_rel_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    lp_pri_list_rank = []\n",
        "    lp_all_list_rank = []\n",
        "\n",
        "    emb_ent, emb_rel, init_embs_ent, init_embs_rel = my_model_wdv2(wdv2.pri_inf.clone().detach(), wdv2.qual_inf.clone().detach(), wdv2.qual2fact_inf, \\\n",
        "                                                              wdv2.num_ent_inf, wdv2.num_rel_inf, \\\n",
        "                                                              wdv2.hpair_inf.clone().detach(), wdv2.hpair_freq_inf, wdv2.fact2hpair_inf, \\\n",
        "                                                              wdv2.tpair_inf.clone().detach(), wdv2.tpair_freq_inf, wdv2.fact2tpair_inf, \\\n",
        "                                                              wdv2.qpair_inf.clone().detach(), wdv2.qpair_freq_inf, wdv2.qual2qpair_inf)\n",
        "    for idxs in tqdm(torch.split(torch.arange(len(wdv2.test_query)), 100)):\n",
        "        query_pri, query_qual, query_qual2fact, \\\n",
        "        query_hpair, query_hpair_freq, query_fact2hpair, \\\n",
        "        query_tpair, query_tpair_freq, query_fact2tpair, \\\n",
        "        query_qpair, query_qpair_freq, query_qual2qpair, \\\n",
        "        answers, pred_locs = wdv2.test_inputs(idxs)\n",
        "        preds = my_model_wdv2.pred(query_pri, query_qual, query_qual2fact, \\\n",
        "                              query_hpair, query_hpair_freq, query_fact2hpair, \\\n",
        "                              query_tpair, query_tpair_freq, query_fact2tpair, \\\n",
        "                              query_qpair, query_qpair_freq, query_qual2qpair, \\\n",
        "                              emb_ent, emb_rel, init_embs_ent, init_embs_rel)\n",
        "        for i, idx in enumerate(idxs):\n",
        "            pred_loc = pred_locs[i]\n",
        "            answer = answers[i] + default_answer\n",
        "            for test_answer in wdv2.test_answer[idx]:\n",
        "                rank = calculate_rank(preds.detach().cpu().numpy()[i], test_answer, answer)\n",
        "                if pred_loc <= 2:\n",
        "                    lp_pri_list_rank.append(rank)\n",
        "                lp_all_list_rank.append(rank)\n",
        "    _, pri_ent_mrr, pri_ent_hit10, _, pri_ent_hit1 = metrics(np.array(lp_pri_list_rank))\n",
        "    _, all_ent_mrr, all_ent_hit10, _, all_ent_hit1 = metrics(np.array(lp_all_list_rank))\n",
        "    print(f\"\\nLink Prediction (Pri, {len(lp_pri_list_rank)})\\nMRR:{pri_ent_mrr:.4f}\\nHit10:{pri_ent_hit10:.4f}\\nHit1:{pri_ent_hit1:.4f}\")\n",
        "    print(f\"Link Prediction (All, {len(lp_all_list_rank)})\\nMRR:{all_ent_mrr:.4f}\\nHit10:{all_ent_hit10:.4f}\\nHit1:{all_ent_hit1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ja9dfNJVd8a",
        "outputId": "87d07681-90b3-4707-b424-440a8614eaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:04<00:00,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Link Prediction (Pri, 1356)\n",
            "MRR:0.2975\n",
            "Hit10:0.5184\n",
            "Hit1:0.1947\n",
            "Link Prediction (All, 2239)\n",
            "MRR:0.4064\n",
            "Hit10:0.6029\n",
            "Hit1:0.3082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}